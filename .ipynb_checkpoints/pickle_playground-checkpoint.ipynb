{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02581674-137d-4ac2-9d30-c93373abf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dependencies\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536d1c7f-0e4a-4de3-991b-a686b42bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more dependencies\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b0396e-22d4-4671-9d66-b453db3a5430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mccal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even more dependencies\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50604bb0-2560-4fbe-a621-72dd87c3c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a set containing all of the english stop words\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa93918-0eb7-4c71-a565-69012fce1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3bb3c5-67cc-4ff0-b43d-c9e1f14cfa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# this pickle holds the serialized emotion detection model that i trained\n",
    "with open('emotion_model.pkl','rb') as file:\n",
    "    emotion_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32a6b45-ff12-4f39-a15d-fd401441e78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccal\\AppData\\Local\\Temp\\ipykernel_2944\\2584208702.py:3: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  vectorizer = pickle.load(file)\n",
      "C:\\Users\\mccal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\mccal\\anaconda3\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.24.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# this is a tfdidf vectorizer that was fit with the training data\n",
    "with open('vectorizer.pkl','rb') as file:\n",
    "    vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98bf572-ec9f-482f-80f1-c93ed3eebe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a data frame that has a vector column that the search algorithm depends on\n",
    "with open('scored_music.pkl','rb') as file:\n",
    "    scored_music = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07bee9a-f1dc-445f-b77f-f0426603941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next i am going to import the functions that allow for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db30b3d-6211-4a2c-a99b-1263fd396dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_score(user_input):\n",
    "    # tokenize the input\n",
    "    input_tokens = nltk.word_tokenize(user_input.lower()) \n",
    "    # filter stopwords out of the input\n",
    "    filtered_input_tokens = [word for word in input_tokens if word not in stop_words] \n",
    "    # re-join the filtered tokens\n",
    "    input_combined = ' '.join(filtered_input_tokens) \n",
    "    # feature extraction\n",
    "    input_vector = vectorizer.transform([input_combined]) \n",
    "    # pull the probabilities from the input\n",
    "    probabilities = emotion_model.predict_proba(input_vector)\n",
    "    # return the probabilities\n",
    "    return probabilities.tolist()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c772a18d-d88f-493a-b136-c5a3c4ee80d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that can compute the similarity between two vectors\n",
    "def song_similarity(u_vec,s_vec):\n",
    "    # convert the song vector into a numpy array\n",
    "    song_array = np.array(s_vec) \n",
    "    # convert the user vector into a numpy array\n",
    "    u_array = np.array(u_vec) \n",
    "    # reshape the song array so it fits into the cosine similarity function\n",
    "    shaped_s_array = np.array(song_array).reshape(1,-1) \n",
    "    # reshape the user array so it fits into the cosine similarity function\n",
    "    shaped_u_array = np.array(u_array).reshape(1,-1) \n",
    "    # compute the similarity\n",
    "    similar = cosine_similarity(shaped_s_array,shaped_u_array) \n",
    "    # the similarity is inside a list inside a list so we need to index it twice\n",
    "    return similar[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99cce8-6178-4109-bd8b-cba4b84077d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed13309d-c214-4bfc-9b14-669b29745c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can play with the search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19e5ad1-c807-47d9-bae1-aec176b1d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0.03579174590286366, 0.8689770047957636, 0.019480216983298226, 0.032564944744232945, 0.023263061565039773, 0.01992302600880187]),\n",
       "       list([0.06429972188393214, 0.6377869365833222, 0.1520119896560907, 0.0530454841641546, 0.06036502570132249, 0.032490842011177856]),\n",
       "       list([0.5374242825027009, 0.31686309768917464, 0.07247709323584733, 0.02208633081018713, 0.02742763237694463, 0.02372156338514537]),\n",
       "       ...,\n",
       "       list([0.16985368845236432, 0.41788928089604205, 0.08971713182181408, 0.13040927733200505, 0.15285628878492602, 0.039274332712848595]),\n",
       "       list([0.2919489066741162, 0.2975261464479545, 0.07445915237974543, 0.20084836550918847, 0.10241929294489283, 0.03279813604410254]),\n",
       "       list([0.3067180083139707, 0.26479157366799827, 0.08410894800858743, 0.2173920374978352, 0.0970364581197081, 0.029952974391900266])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = scored_music['vector'].values\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bcce8eb-a203-402b-b0fd-ba193fe01416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03579175, 0.868977  , 0.01948022, 0.03256494, 0.02326306,\n",
       "        0.01992303],\n",
       "       [0.06429972, 0.63778694, 0.15201199, 0.05304548, 0.06036503,\n",
       "        0.03249084],\n",
       "       [0.53742428, 0.3168631 , 0.07247709, 0.02208633, 0.02742763,\n",
       "        0.02372156],\n",
       "       ...,\n",
       "       [0.16985369, 0.41788928, 0.08971713, 0.13040928, 0.15285629,\n",
       "        0.03927433],\n",
       "       [0.29194891, 0.29752615, 0.07445915, 0.20084837, 0.10241929,\n",
       "        0.03279814],\n",
       "       [0.30671801, 0.26479157, 0.08410895, 0.21739204, 0.09703646,\n",
       "        0.02995297]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_vectors=np.vstack(scored_music['vector'].values)\n",
    "song_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b718ca78-cdfc-4f90-a801-cf9403eb1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity([[1,1,1,1,1,1]],song_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40314065-2f05-48e3-88a2-596c6ca43b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that can compute the similarity between two vectors\n",
    "def song_similarity(u_vec,s_vec):\n",
    "    \n",
    "    u_array = np.array(u_vec) \n",
    "    \n",
    "    # reshape the user array so it fits into the cosine similarity function\n",
    "    shaped_u_array = np.array(u_array).reshape(1,-1) \n",
    "    # compute the similarity\n",
    "    similar = cosine_similarity(shaped_u_array,s_vec) \n",
    "    # the similarity is inside a list inside a list so we need to index it twice\n",
    "    return similar[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f84b3d2d-9a2f-46fc-8890-caace391a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = emotion_score('test vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a853af9-0af6-4191-b8f6-c98718483a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18414672908266747,\n",
       " 0.3895595545424753,\n",
       " 0.06683270158820262,\n",
       " 0.184455173813241,\n",
       " 0.13719782268369984,\n",
       " 0.03780801828971377]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af5f50e1-7fba-41ee-aa8b-4a32615723e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18414673, 0.38955955, 0.0668327 , 0.18445517, 0.13719782,\n",
       "       0.03780802])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.array(test_vector)\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5562540c-b91e-4421-8dbf-3136ed2a7686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18414673, 0.38955955, 0.0668327 , 0.18445517, 0.13719782,\n",
       "        0.03780802]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaped_test_array = test_array.reshape(1,-1)\n",
    "shaped_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2c8bb8f-aafd-4498-af81-75d65a527d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46866918, 0.61439179, 0.64851759, ..., 0.81092842, 0.84903417,\n",
       "       0.85341621])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0da9666f-d8f6-44fb-8a6e-03f7e24cbd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.03579174590286366, 0.8689770047957636, 0.01...\n",
       "1        [0.06429972188393214, 0.6377869365833222, 0.15...\n",
       "2        [0.5374242825027009, 0.31686309768917464, 0.07...\n",
       "3        [0.13480472056337753, 0.36512886018708607, 0.2...\n",
       "4        [0.9674123512465452, 0.00520893792719057, 0.01...\n",
       "                               ...                        \n",
       "44790    [0.15062559050424443, 0.5088407635755823, 0.05...\n",
       "44791    [0.438188434704547, 0.1918744712386625, 0.0303...\n",
       "44792    [0.16985368845236432, 0.41788928089604205, 0.0...\n",
       "44793    [0.2919489066741162, 0.2975261464479545, 0.074...\n",
       "44794    [0.3067180083139707, 0.26479157366799827, 0.08...\n",
       "Name: vector, Length: 44795, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_music['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0efd488-875a-4c19-b75e-84c6c4c7d575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0.03579174590286366, 0.8689770047957636, 0.019480216983298226, 0.032564944744232945, 0.023263061565039773, 0.01992302600880187]),\n",
       "       list([0.06429972188393214, 0.6377869365833222, 0.1520119896560907, 0.0530454841641546, 0.06036502570132249, 0.032490842011177856]),\n",
       "       list([0.5374242825027009, 0.31686309768917464, 0.07247709323584733, 0.02208633081018713, 0.02742763237694463, 0.02372156338514537]),\n",
       "       ...,\n",
       "       list([0.16985368845236432, 0.41788928089604205, 0.08971713182181408, 0.13040927733200505, 0.15285628878492602, 0.039274332712848595]),\n",
       "       list([0.2919489066741162, 0.2975261464479545, 0.07445915237974543, 0.20084836550918847, 0.10241929294489283, 0.03279813604410254]),\n",
       "       list([0.3067180083139707, 0.26479157366799827, 0.08410894800858743, 0.2173920374978352, 0.0970364581197081, 0.029952974391900266])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = scored_music['vector'].values\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8732ed66-dbd7-4225-b4c5-a9fb96602a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03579175, 0.868977  , 0.01948022, 0.03256494, 0.02326306,\n",
       "        0.01992303],\n",
       "       [0.06429972, 0.63778694, 0.15201199, 0.05304548, 0.06036503,\n",
       "        0.03249084],\n",
       "       [0.53742428, 0.3168631 , 0.07247709, 0.02208633, 0.02742763,\n",
       "        0.02372156],\n",
       "       ...,\n",
       "       [0.16985369, 0.41788928, 0.08971713, 0.13040928, 0.15285629,\n",
       "        0.03927433],\n",
       "       [0.29194891, 0.29752615, 0.07445915, 0.20084837, 0.10241929,\n",
       "        0.03279814],\n",
       "       [0.30671801, 0.26479157, 0.08410895, 0.21739204, 0.09703646,\n",
       "        0.02995297]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_stack = np.vstack(vectors)\n",
    "song_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79f458e7-dc63-4250-80b0-14cd777cbb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44795, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df04a676-bbee-4ef4-8995-b557ad2c9fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaped_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8c6299-7a9e-481b-995d-b0cd9bfe4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_search_x(user_input):\n",
    "    \n",
    "    # Convert the user's input into a vector \n",
    "    user_vector = emotion_score(user_input)\n",
    "    \n",
    "    # Ensure scored_music DataFrame has a column for vectors\n",
    "    if 'vector' not in scored_music.columns:\n",
    "        raise ValueError(\"scored_music DataFrame must have a 'vector' column containing song vectors.\")\n",
    "    \n",
    "    # Convert the list of vectors from the scored_music DataFrame into a matrix\n",
    "    song_vectors = np.vstack(scored_music['vector'].values)\n",
    "    \n",
    "    # Calculate cosine similarity for the entire set of song vectors at once\n",
    "    cos_sim = cosine_similarity([user_vector], song_vectors)[0]\n",
    "    # tbh idk what the fuck this line is actually doing chatgpt wrote it\n",
    "    # works great though\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame to store the similarity scores along with song and artist info\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'similarity': cos_sim,\n",
    "        'track': scored_music['song'],\n",
    "        'artist': scored_music['artist']\n",
    "    })\n",
    "    \n",
    "    # Sort by similarity in descending order\n",
    "    sorted_comparison_df = comparison_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # return the top 10\n",
    "    return sorted_comparison_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9919c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>All The Small Things (Blink 182 Cover)</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20823</th>\n",
       "      <td>0.999660</td>\n",
       "      <td>Sana Kahit Minsan</td>\n",
       "      <td>Ariel Rivera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15332</th>\n",
       "      <td>0.999538</td>\n",
       "      <td>Kung Maibabalik Ko Lang</td>\n",
       "      <td>Regine Velasquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37931</th>\n",
       "      <td>0.999395</td>\n",
       "      <td>Liberation</td>\n",
       "      <td>Pet Shop Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14739</th>\n",
       "      <td>0.999193</td>\n",
       "      <td>Yah Mo B There</td>\n",
       "      <td>Quincy Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15345</th>\n",
       "      <td>0.999148</td>\n",
       "      <td>Say You Love Me</td>\n",
       "      <td>Regine Velasquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>0.999069</td>\n",
       "      <td>Taning</td>\n",
       "      <td>Imago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30670</th>\n",
       "      <td>0.998985</td>\n",
       "      <td>Stone Walls</td>\n",
       "      <td>Jim Croce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>0.998777</td>\n",
       "      <td>Minsan, Isang Kahapon</td>\n",
       "      <td>Lea Salonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37836</th>\n",
       "      <td>0.998755</td>\n",
       "      <td>Hunger Strike</td>\n",
       "      <td>Pearl Jam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity                                   track            artist\n",
       "878      0.999781  All The Small Things (Blink 182 Cover)     Avril Lavigne\n",
       "20823    0.999660                       Sana Kahit Minsan      Ariel Rivera\n",
       "15332    0.999538                 Kung Maibabalik Ko Lang  Regine Velasquez\n",
       "37931    0.999395                              Liberation     Pet Shop Boys\n",
       "14739    0.999193                          Yah Mo B There      Quincy Jones\n",
       "15345    0.999148                         Say You Love Me  Regine Velasquez\n",
       "7624     0.999069                                  Taning             Imago\n",
       "30670    0.998985                             Stone Walls         Jim Croce\n",
       "10184    0.998777                   Minsan, Isang Kahapon       Lea Salonga\n",
       "37836    0.998755                           Hunger Strike         Pearl Jam"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
