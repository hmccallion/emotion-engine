{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce65c0ee-1f63-4339-847e-3671aefacaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ea1211-1d45-4642-9932-09bf9b183c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenize will turn each word in a text string into a token\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f1a137-0923-4cd5-9db2-7c11eb5df519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mccal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punkt is a language aware model that can handle punctuation in text\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a68356-4930-4c7b-bab9-b54aa385cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i don't think there is any punctuation in the data that we are using to train this model but best to be safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16fbf0ca-57c5-4fbd-b016-4d9f897fb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mccal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are definitely stop words in the data we will use to build the model (words that do not have sentiment)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5af6fac-07e9-47ea-a358-9382e61e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this weighs the importance of a word based on freqeuency (feature extraction tool)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6ac302-73ee-4a51-b15d-f2289b51b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we all know what this is\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e911b8-c320-4ef0-964b-49ee30af319b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # this is our model of choice\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e8b31c-2c59-4ac6-a203-fdb92d6c902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this to see how accurate the model is\n",
    "from sklearn.metrics import accuracy_score, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d3c9cc-514d-485a-a2f5-50585285688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in labeled text data to make the model\n",
    "emotions=pd.read_csv('emotions.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83118472-2494-484c-a92d-97764e5803ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416809 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416809 non-null  object\n",
      " 1   label   416809 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# basic data information\n",
    "emotions.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c284e670-454f-42a6-ba34-3f82c04e501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0      i just feel really helpless and heavy hearted      4\n",
       "1  ive enjoyed being able to slouch about relax a...      0\n",
       "2  i gave up my internship with the dmrg and am f...      4\n",
       "3                         i dont know i feel so lost      0\n",
       "4  i am a kindergarten teacher and i am thoroughl...      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's what the data looks like\n",
    "emotions.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c7dad2-3fff-4622-bf46-b657fd4b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5) emotions and their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "314b30f9-b76b-4a47-b59e-d0902572ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    141067\n",
       "0    121187\n",
       "3     57317\n",
       "4     47712\n",
       "2     34554\n",
       "5     14972\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have some really unbalanced data here, this is what we adress first if we want to improve the model\n",
    "emotions.label.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6960ecef-228c-4523-96be-ac7ae8b79e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i am writing a function that tokenizes text that we can apply to the text column\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60f29520-98e1-4b9c-ab45-51bd9db5e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the tokenizer function to create a tokens column\n",
    "emotions['tokens']=emotions['text'].apply(tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f37494-12ad-4010-bf99-5389a0f02566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a set containing all of the english stop words\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ea2618-96b0-4837-9176-d6b13f87f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are creating a column of tokens that do not contain any words we do not want to feed the model\n",
    "emotions['filtered_tokens'] = emotions['tokens'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f67382-9f67-4647-88c0-e693d8005a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, just, feel, really, helpless, and, heavy, ...</td>\n",
       "      <td>[feel, really, helpless, heavy, hearted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ive, enjoyed, being, able, to, slouch, about,...</td>\n",
       "      <td>[ive, enjoyed, able, slouch, relax, unwind, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, gave, up, my, internship, with, the, dmrg,...</td>\n",
       "      <td>[gave, internship, dmrg, feeling, distraught]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, dont, know, i, feel, so, lost]</td>\n",
       "      <td>[dont, know, feel, lost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, am, a, kindergarten, teacher, and, i, am, ...</td>\n",
       "      <td>[kindergarten, teacher, thoroughly, weary, job...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0      i just feel really helpless and heavy hearted      4   \n",
       "1  ive enjoyed being able to slouch about relax a...      0   \n",
       "2  i gave up my internship with the dmrg and am f...      4   \n",
       "3                         i dont know i feel so lost      0   \n",
       "4  i am a kindergarten teacher and i am thoroughl...      4   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, just, feel, really, helpless, and, heavy, ...   \n",
       "1  [ive, enjoyed, being, able, to, slouch, about,...   \n",
       "2  [i, gave, up, my, internship, with, the, dmrg,...   \n",
       "3                 [i, dont, know, i, feel, so, lost]   \n",
       "4  [i, am, a, kindergarten, teacher, and, i, am, ...   \n",
       "\n",
       "                                     filtered_tokens  \n",
       "0           [feel, really, helpless, heavy, hearted]  \n",
       "1  [ive, enjoyed, able, slouch, relax, unwind, fr...  \n",
       "2      [gave, internship, dmrg, feeling, distraught]  \n",
       "3                           [dont, know, feel, lost]  \n",
       "4  [kindergarten, teacher, thoroughly, weary, job...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # here's what our data looks like now with the new features\n",
    "emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08fd9246-af8f-4881-b549-38cd48bdbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's happening here is we are creating a column combining the filtered tokens back together into a text string\n",
    "emotions['text_combined'] = emotions['filtered_tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72b6cb34-14ca-4684-81ea-5cb84c1b170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i mentioned earlier that this is going to make the text readable for the logistic regression  model\n",
    "# this is going to create vectors from our text that we can use for training\n",
    "# the vectors are made with term frequency, relative to amount of documents, which in turn tells us something about their importance\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd19310-7319-4b29-8c42-87c9ecc5c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text\n",
    "X = vectorizer.fit_transform(emotions['text_combined']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daaf7f07-34af-44e2-91a3-9cc75071076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=emotions['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5239631a-de39-45dc-9625-f21851492186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training data and testing data\n",
    "# 42 was chosen arbitrarily\n",
    "# random state accepts any number in range [-2,147,483,648 , 2,147,483,647]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9282b8ef-2822-4259-8c41-974051eaf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is 'l2'\n",
    "# i chose 200 for max_iter because it was large enough to reach convergence\n",
    "# if you do not set the max_iter to 200, the default, 100 is not enough and you will get an error\n",
    "model = LogisticRegression(penalty='l2', max_iter=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "146fd7f5-1bb0-478c-a0f5-4039c9430673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccal\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3257f872-5d30-47d3-9b4d-9af0e2c75ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic prediction function call\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c6894b-c026-4d07-a268-d60bba2c4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02eb8c38-22ce-4ef4-9a67-4472a4630017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8939684748446535"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did pretty well\n",
    "accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb1359fc-3e24-435f-b6ee-c93a7a76a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we aren't after the models prediction for the labels\n",
    "# we are after the probability scores for each label because we want nuanced emotion vectors\n",
    "# lets do a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baa1efc0-8053-4501-8278-c4236276b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a string that i am going to write that will contain some things i want to say about my emotional state\n",
    "hank_feeling = 'i had a stressfull day but i was able to get a lot done which made me proud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4961e653-5005-4e56-90f1-efaa2605ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to pull an emotion vector from this string we need to apply the same principles we used to train the model\n",
    "# we need to tokenize the text\n",
    "# we need to filter the tokenized text for stopwords\n",
    "# we need to re join that filtered token into plain text\n",
    "# we need to extract features using tfidf vectorization\n",
    "# we need to tell the model to predict probabilites NOT the label\n",
    "# we're gonna investigate what the probabilities look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e292372b-f28e-4714-9a98-08c9a6af4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  recall this key; sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5) emotions and their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07ae7a7d-b5d0-43dc-a89b-4e84b5be4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a function that does that whole process for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1fb3c98-ef69-4f90-a0c7-1b24f540fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_score(user_input):\n",
    "    # tokenize the input\n",
    "    input_tokens = nltk.word_tokenize(user_input.lower()) \n",
    "    # filter stopwords out of the input\n",
    "    filtered_input_tokens = [word for word in input_tokens if word not in stop_words] \n",
    "    # re-join the filtered tokens\n",
    "    input_combined = ' '.join(filtered_input_tokens) \n",
    "    # feature extraction\n",
    "    input_vector = vectorizer.transform([input_combined]) \n",
    "    # pull the probabilities from the input\n",
    "    probabilities = model.predict_proba(input_vector)\n",
    "    # return the probabilities\n",
    "    return probabilities.tolist()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7918448e-3f19-4624-938c-836aa0a5f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014172429431486432,\n",
       " 0.9566514104423582,\n",
       " 0.008914546684369156,\n",
       " 0.008687934455954609,\n",
       " 0.0048888348324429304,\n",
       " 0.00668484415338865]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_score(hank_feeling) # test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab94086c-a672-4f88-b973-18a3126c065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i wanna run this function on an entire data frame of song lyrics\n",
    "music=pd.read_csv('songs_with_lyrics_Cleaned.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9226bb13-8fa9-4dd3-8d8f-0c4eda91b48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>look at her face, it's a wonderful face and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>take it easy with me, please touch me gently l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>i'll never know why i had to go why i had to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 artist                   song  \\\n",
       "0           0   ABBA  Ahe's My Kind Of Girl   \n",
       "1           1   ABBA       Andante, Andante   \n",
       "2           2   ABBA         As Good As New   \n",
       "3           3   ABBA                   Bang   \n",
       "4           4   ABBA       Bang-A-Boomerang   \n",
       "\n",
       "                                         link  \\\n",
       "0  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1       /a/abba/andante+andante_20002708.html   \n",
       "2        /a/abba/as+good+as+new_20003033.html   \n",
       "3                  /a/abba/bang_20598415.html   \n",
       "4      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  look at her face, it's a wonderful face and it...  \n",
       "1  take it easy with me, please touch me gently l...  \n",
       "2  i'll never know why i had to go why i had to p...  \n",
       "3  making somebody happy is a question of give an...  \n",
       "4  making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # here's what the data frame with music data and song lyrics\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65d0821d-2e38-4ae7-b0b1-149c92fd9792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7344534623529986,\n",
       " 0.13323336314786657,\n",
       " 0.02990271648282762,\n",
       " 0.04125990395442898,\n",
       " 0.03311831665915752,\n",
       " 0.02803223740272064]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo for how the song handles user input\n",
    "emotion_score(' i had a pretty rough day, can you recommend me a sad song?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e95ebb7e-0d41-4e89-8096-e8ccd1d619a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that vectorizes the song lyric data with an emotion score dictionary in order to create a table for the lyric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9568a222-80eb-407c-80b7-9c50b77e9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_dictionary(user_input):\n",
    "    # make tokens\n",
    "    input_tokens = nltk.word_tokenize(user_input.lower()) \n",
    "    # filter the tokens\n",
    "    filtered_input_tokens = [word for word in input_tokens if word not in stop_words] \n",
    "    # recombine filtered tokens\n",
    "    input_combined = ' '.join(filtered_input_tokens) \n",
    "    # tfidf feature extraction\n",
    "    input_vector = vectorizer.transform([input_combined]) \n",
    "    # call the probabilities\n",
    "    probabilities = model.predict_proba(input_vector) \n",
    "    # create the vector\n",
    "    emotion_vector = probabilities.tolist()[0] \n",
    "    # use the vector to create a dictionary with the scores and a key that references the scores\n",
    "    return {'sadness': emotion_vector[0], \n",
    "    'joy': emotion_vector[1],\n",
    "    'love': emotion_vector[2],\n",
    "    'anger': emotion_vector[3],\n",
    "    'fear': emotion_vector[4],\n",
    "    'surprise': emotion_vector[5] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1652f7e9-3625-447e-a860-cf2114b12e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to make the score table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d69c974-6b64-4a56-bbd6-14ae461fe6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8e4bc40-9702-41e1-af70-922291982cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call this to get the progress bar\n",
    "tqdm.pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c56dea62-e820-43d3-9a0f-090998eda026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 44795/44795 [05:33<00:00, 134.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# get a series containing the emotion scores for every song\n",
    "scores=music['text'].progress_apply(emotion_dictionary).apply(pd.Series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4bbfe22-c083-41a0-81f4-7bf24b45d726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035792</td>\n",
       "      <td>0.868977</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.019923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.637787</td>\n",
       "      <td>0.152012</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.060365</td>\n",
       "      <td>0.032491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537424</td>\n",
       "      <td>0.316863</td>\n",
       "      <td>0.072477</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.027428</td>\n",
       "      <td>0.023722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134805</td>\n",
       "      <td>0.365129</td>\n",
       "      <td>0.266093</td>\n",
       "      <td>0.142332</td>\n",
       "      <td>0.064678</td>\n",
       "      <td>0.026963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967412</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44790</th>\n",
       "      <td>0.150626</td>\n",
       "      <td>0.508841</td>\n",
       "      <td>0.054495</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>0.109686</td>\n",
       "      <td>0.035241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>0.438188</td>\n",
       "      <td>0.191874</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.196898</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44792</th>\n",
       "      <td>0.169854</td>\n",
       "      <td>0.417889</td>\n",
       "      <td>0.089717</td>\n",
       "      <td>0.130409</td>\n",
       "      <td>0.152856</td>\n",
       "      <td>0.039274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>0.291949</td>\n",
       "      <td>0.297526</td>\n",
       "      <td>0.074459</td>\n",
       "      <td>0.200848</td>\n",
       "      <td>0.102419</td>\n",
       "      <td>0.032798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44794</th>\n",
       "      <td>0.306718</td>\n",
       "      <td>0.264792</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.217392</td>\n",
       "      <td>0.097036</td>\n",
       "      <td>0.029953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44795 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sadness       joy      love     anger      fear  surprise\n",
       "0      0.035792  0.868977  0.019480  0.032565  0.023263  0.019923\n",
       "1      0.064300  0.637787  0.152012  0.053045  0.060365  0.032491\n",
       "2      0.537424  0.316863  0.072477  0.022086  0.027428  0.023722\n",
       "3      0.134805  0.365129  0.266093  0.142332  0.064678  0.026963\n",
       "4      0.967412  0.005209  0.016959  0.006574  0.002430  0.001416\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "44790  0.150626  0.508841  0.054495  0.141112  0.109686  0.035241\n",
       "44791  0.438188  0.191874  0.030315  0.196898  0.095205  0.047519\n",
       "44792  0.169854  0.417889  0.089717  0.130409  0.152856  0.039274\n",
       "44793  0.291949  0.297526  0.074459  0.200848  0.102419  0.032798\n",
       "44794  0.306718  0.264792  0.084109  0.217392  0.097036  0.029953\n",
       "\n",
       "[44795 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the scores data series that we will concat to our original data frame\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc104d0d-9531-49c6-9947-3b32964e5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the scores to the music to get a df with the scores\n",
    "scored_music=pd.concat([music,scores],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81c76775-c315-4b9f-aae7-61236782eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless column\n",
    "scored_music.drop(columns=['Unnamed: 0'],inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6c2e014-9a32-465d-929c-b5be069c2293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 44795/44795 [05:47<00:00, 128.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# we also want a column with just the vectors\n",
    "vector=music['text'].progress_apply(emotion_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b33929-f791-4d6b-82fc-42d866099f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.03579174590286366, 0.8689770047957636, 0.01...\n",
       "1        [0.06429972188393214, 0.6377869365833222, 0.15...\n",
       "2        [0.5374242825027009, 0.31686309768917464, 0.07...\n",
       "3        [0.13480472056337753, 0.36512886018708607, 0.2...\n",
       "4        [0.9674123512465452, 0.00520893792719057, 0.01...\n",
       "                               ...                        \n",
       "44790    [0.15062559050424443, 0.5088407635755823, 0.05...\n",
       "44791    [0.438188434704547, 0.1918744712386625, 0.0303...\n",
       "44792    [0.16985368845236432, 0.41788928089604205, 0.0...\n",
       "44793    [0.2919489066741162, 0.2975261464479545, 0.074...\n",
       "44794    [0.3067180083139707, 0.26479157366799827, 0.08...\n",
       "Name: text, Length: 44795, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vector for each song in the data set\n",
    "vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73818238-ca89-46a7-a8e3-5f771ce7f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column to store the vectors\n",
    "scored_music['vector']=vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06a09800-d232-4ad9-ab2d-e4f8a03cd743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44061</th>\n",
       "      <td>Wishbone Ash</td>\n",
       "      <td>Can't Fight Love</td>\n",
       "      <td>/w/wishbone+ash/cant+fight+love_20147313.html</td>\n",
       "      <td>i don't care about no curfew tonight - i just ...</td>\n",
       "      <td>0.135844</td>\n",
       "      <td>0.419008</td>\n",
       "      <td>0.097972</td>\n",
       "      <td>0.125352</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0.038618</td>\n",
       "      <td>[0.1358438472028008, 0.41900769291534823, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26683</th>\n",
       "      <td>Face To Face</td>\n",
       "      <td>10-9-8</td>\n",
       "      <td>/f/face+to+face/10+9+8_20149571.html</td>\n",
       "      <td>i'll be your loaded dice you're holding all th...</td>\n",
       "      <td>0.194766</td>\n",
       "      <td>0.147385</td>\n",
       "      <td>0.098991</td>\n",
       "      <td>0.103784</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.240875</td>\n",
       "      <td>[0.19476599608244413, 0.14738528633766504, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23387</th>\n",
       "      <td>Christmas Songs</td>\n",
       "      <td>Born On Christmas Day</td>\n",
       "      <td>/c/christmas+songs/born+on+christmas+day_20767...</td>\n",
       "      <td>it was a cold and dark december night but a st...</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>0.616557</td>\n",
       "      <td>0.102805</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.083208</td>\n",
       "      <td>0.038846</td>\n",
       "      <td>[0.08414342313057617, 0.6165571934188573, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12977</th>\n",
       "      <td>Oasis</td>\n",
       "      <td>Keep The Dream Alive</td>\n",
       "      <td>/o/oasis/keep+the+dream+alive_10196341.html</td>\n",
       "      <td>four seasons, seconds, flicker, and flash, i'm...</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.075932</td>\n",
       "      <td>0.096160</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.196037</td>\n",
       "      <td>0.075016</td>\n",
       "      <td>[0.47485912131492175, 0.07593164065044197, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42525</th>\n",
       "      <td>Underworld</td>\n",
       "      <td>Show Some Emotion</td>\n",
       "      <td>/u/underworld/show+some+emotion_20142185.html</td>\n",
       "      <td>wait you've gone too far who for god's sake wh...</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.508163</td>\n",
       "      <td>0.039031</td>\n",
       "      <td>0.281315</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>[0.09925820948350259, 0.5081632207990925, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                   song  \\\n",
       "44061     Wishbone Ash       Can't Fight Love   \n",
       "26683     Face To Face                 10-9-8   \n",
       "23387  Christmas Songs  Born On Christmas Day   \n",
       "12977            Oasis   Keep The Dream Alive   \n",
       "42525       Underworld      Show Some Emotion   \n",
       "\n",
       "                                                    link  \\\n",
       "44061      /w/wishbone+ash/cant+fight+love_20147313.html   \n",
       "26683               /f/face+to+face/10+9+8_20149571.html   \n",
       "23387  /c/christmas+songs/born+on+christmas+day_20767...   \n",
       "12977        /o/oasis/keep+the+dream+alive_10196341.html   \n",
       "42525      /u/underworld/show+some+emotion_20142185.html   \n",
       "\n",
       "                                                    text   sadness       joy  \\\n",
       "44061  i don't care about no curfew tonight - i just ...  0.135844  0.419008   \n",
       "26683  i'll be your loaded dice you're holding all th...  0.194766  0.147385   \n",
       "23387  it was a cold and dark december night but a st...  0.084143  0.616557   \n",
       "12977  four seasons, seconds, flicker, and flash, i'm...  0.474859  0.075932   \n",
       "42525  wait you've gone too far who for god's sake wh...  0.099258  0.508163   \n",
       "\n",
       "           love     anger      fear  surprise  \\\n",
       "44061  0.097972  0.125352  0.183206  0.038618   \n",
       "26683  0.098991  0.103784  0.214200  0.240875   \n",
       "23387  0.102805  0.074441  0.083208  0.038846   \n",
       "12977  0.096160  0.081997  0.196037  0.075016   \n",
       "42525  0.039031  0.281315  0.049071  0.023162   \n",
       "\n",
       "                                                  vector  \n",
       "44061  [0.1358438472028008, 0.41900769291534823, 0.09...  \n",
       "26683  [0.19476599608244413, 0.14738528633766504, 0.0...  \n",
       "23387  [0.08414342313057617, 0.6165571934188573, 0.10...  \n",
       "12977  [0.47485912131492175, 0.07593164065044197, 0.0...  \n",
       "42525  [0.09925820948350259, 0.5081632207990925, 0.03...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our final dataframe\n",
    "scored_music.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a8c08cb-5df5-4f9e-8f52-53e86ce840d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the similarity algorithm for vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e161008-a4c9-4e82-96c4-59b9d46e7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_input='yesterday i watched the lakers game and i lost money on it which was rough but i had fun watching the game anyways which was good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8919c9a-baff-4ec8-a2e8-6a43ebff5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that can compute the similarity between two vectors\n",
    "def song_similarity(u_vec,s_vec):\n",
    "    # convert the song vector into a numpy array\n",
    "    song_array = np.array(s_vec) \n",
    "    # convert the user vector into a numpy array\n",
    "    u_array = np.array(u_vec) \n",
    "    # reshape the song array so it fits into the cosine similarity function\n",
    "    shaped_s_array = np.array(song_array).reshape(1,-1) \n",
    "    # reshape the user array so it fits into the cosine similarity function\n",
    "    shaped_u_array = np.array(u_array).reshape(1,-1) \n",
    "    # compute the similarity\n",
    "    similar = cosine_similarity(shaped_s_array,shaped_u_array) \n",
    "    # the similarity is inside a list inside a list so we need to index it twice\n",
    "    return similar[0][0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "884e22ba-939f-4f7f-85d2-7039688a9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a function that does the similarity search\n",
    "\n",
    "def cosine_similarity_search(user_input):\n",
    "    # the function takes in user input then turns it into a vector\n",
    "    user_vector = emotion_score(user_input) \n",
    "    # it initializes a list called comparison\n",
    "    comparison = [] \n",
    "    # it opens a loop that iterates through the length of the scored music data\n",
    "    for i in range(len(scored_music)):  \n",
    "        # the loop initializes a list that hold the similarity to the user vector song and artist\n",
    "        user_vs_song=[] \n",
    "        \n",
    "        # then the cosine similarity between the user vector and song vector is computed and stored as a variable \n",
    "        cos_sim = song_similarity(user_vector,scored_music['vector'][i]) \n",
    "        # the song name is stored to a variable\n",
    "        song_name = scored_music['song'][i] \n",
    "        # the artist name is stored to a variable\n",
    "        artist_name = scored_music['artist'][i] \n",
    "        \n",
    "        # these three variables are appended to the user_vs_song list\n",
    "        user_vs_song.append(cos_sim)\n",
    "        user_vs_song.append(song_name)\n",
    "        user_vs_song.append(artist_name)\n",
    "        \n",
    "        # the user_vs_song list is appended to the comparison list to later be sorted\n",
    "        comparison.append(user_vs_song)\n",
    "\n",
    "    # once the loop is done executing we convert our comparison list into a data frame so it can be sorted easiliy\n",
    "    comp_df=pd.DataFrame(comparison,columns=['similarity','track','artist'])\n",
    "    \n",
    "    # return the sorted df\n",
    "    return comp_df.sort_values(by='similarity',ascending=False)#.head(50).sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45f520ad-2241-4c34-8fe2-eafa5d6aeb0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27522</th>\n",
       "      <td>0.999721</td>\n",
       "      <td>Entangled</td>\n",
       "      <td>Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41486</th>\n",
       "      <td>0.999568</td>\n",
       "      <td>Think About The Times</td>\n",
       "      <td>Ten Years After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>0.999169</td>\n",
       "      <td>What Do I Get?</td>\n",
       "      <td>Everclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>0.999082</td>\n",
       "      <td>My Woman</td>\n",
       "      <td>Chuck Berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31264</th>\n",
       "      <td>0.999048</td>\n",
       "      <td>Drums</td>\n",
       "      <td>Johnny Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30424</th>\n",
       "      <td>0.074414</td>\n",
       "      <td>Love Me, Lovely</td>\n",
       "      <td>Jackson Browne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23277</th>\n",
       "      <td>0.074409</td>\n",
       "      <td>One Sweet Tender Touch</td>\n",
       "      <td>Chris Rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20747</th>\n",
       "      <td>0.074404</td>\n",
       "      <td>Tender Is The Night</td>\n",
       "      <td>Andy Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>0.074396</td>\n",
       "      <td>Hot In Here</td>\n",
       "      <td>Rascal Flatts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>0.074388</td>\n",
       "      <td>Tender Love</td>\n",
       "      <td>Backstreet Boys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44795 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity                   track           artist\n",
       "27522    0.999721               Entangled          Genesis\n",
       "41486    0.999568   Think About The Times  Ten Years After\n",
       "5302     0.999169          What Do I Get?        Everclear\n",
       "2943     0.999082                My Woman      Chuck Berry\n",
       "31264    0.999048                   Drums      Johnny Cash\n",
       "...           ...                     ...              ...\n",
       "30424    0.074414         Love Me, Lovely   Jackson Browne\n",
       "23277    0.074409  One Sweet Tender Touch        Chris Rea\n",
       "20747    0.074404     Tender Is The Night    Andy Williams\n",
       "15078    0.074396             Hot In Here    Rascal Flatts\n",
       "21029    0.074388             Tender Love  Backstreet Boys\n",
       "\n",
       "[44795 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_search(sample_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3889f356-b9bf-42bb-8dde-262d8844fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6da3ba92-bb0c-433f-8f97-a17cef239ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_distance(u_vec,s_vec):\n",
    "    # convert the song vector into a numpy array\n",
    "    song_array = np.array(s_vec) \n",
    "    # convert the user vector into a numpy array\n",
    "    u_array = np.array(u_vec) \n",
    "    # reshape the song array so it fits into the distance function\n",
    "    shaped_s_array = np.array(song_array).reshape(1,-1) \n",
    "    # reshape the user array so it fits into the distance function\n",
    "    shaped_u_array = np.array(u_array).reshape(1,-1) \n",
    "    # compute the distance\n",
    "    similar =  euclidean_distances(shaped_s_array,shaped_u_array) \n",
    "    # the distance is inside a list inside a list so we need to index it twice\n",
    "    return similar[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20916d3d-e156-4c4f-a06d-042e102551f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_search(user_input):\n",
    "    # vectorize the user input\n",
    "    user_vector = emotion_score(user_input) \n",
    "    # initilize list that can compare the distances\n",
    "    comparison = [] \n",
    "    \n",
    "    for i in range(len(scored_music)):\n",
    "        # initilize list that stores the distance song and artist\n",
    "        user_vs_song = [] \n",
    "        # compute the distance\n",
    "        euclid_distance = song_distance(user_vector,scored_music['vector'][i]) \n",
    "        # save song name to variable\n",
    "        song_name = scored_music['song'][i] \n",
    "        # save artist name to a variable\n",
    "        artist_name = scored_music['artist'][i] \n",
    "        # append distance\n",
    "        user_vs_song.append(euclid_distance) \n",
    "        # append song\n",
    "        user_vs_song.append(song_name) \n",
    "        # append artist\n",
    "        user_vs_song.append(artist_name) \n",
    "        # throw all that info into the compairson list\n",
    "        comparison.append(user_vs_song) \n",
    "    # make the comparison list into a data frame\n",
    "    comp_df = pd.DataFrame(comparison, columns=['distance','track','artist']) \n",
    "    # return the df sorted by the distance in ascending order\n",
    "    return comp_df.sort_values(by='distance') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca6f8420-a68f-4c61-860f-b3a8d8da6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pickle to pickle the variables instead of joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "688e7509-cf71-4cd3-9e5d-4feeb13db8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aaca0fe6-5ce0-4d74-bd1c-d589efd242b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be697e1f-8aff-4396-8476-243d8b15c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl','wb') as file:\n",
    "    pickle.dump(vectorizer,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f76de32-d92f-47e9-9e4b-7d9ced448980",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scored_music.pkl','wb') as file:\n",
    "    pickle.dump(scored_music,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d27813-3e54-4a6f-b6f7-d15c1c046812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
