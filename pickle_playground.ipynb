{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02581674-137d-4ac2-9d30-c93373abf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dependencies\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536d1c7f-0e4a-4de3-991b-a686b42bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more dependencies\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b0396e-22d4-4671-9d66-b453db3a5430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mccal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even more dependencies\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50604bb0-2560-4fbe-a621-72dd87c3c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a set containing all of the english stop words\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa93918-0eb7-4c71-a565-69012fce1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3bb3c5-67cc-4ff0-b43d-c9e1f14cfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this pickle holds the serialized emotion detection model that i trained\n",
    "with open('emotion_model.pkl','rb') as file:\n",
    "    emotion_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32a6b45-ff12-4f39-a15d-fd401441e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a tfdidf vectorizer that was fit with the training data\n",
    "with open('vectorizer.pkl','rb') as file:\n",
    "    vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98bf572-ec9f-482f-80f1-c93ed3eebe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a data frame that has a vector column that the search algorithm depends on\n",
    "with open('scored_music.pkl','rb') as file:\n",
    "    scored_music = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07bee9a-f1dc-445f-b77f-f0426603941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next i am going to import the functions that allow for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db30b3d-6211-4a2c-a99b-1263fd396dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_score(user_input):\n",
    "    # tokenize the input\n",
    "    input_tokens = nltk.word_tokenize(user_input.lower()) \n",
    "    # filter stopwords out of the input\n",
    "    filtered_input_tokens = [word for word in input_tokens if word not in stop_words] \n",
    "    # re-join the filtered tokens\n",
    "    input_combined = ' '.join(filtered_input_tokens) \n",
    "    # feature extraction\n",
    "    input_vector = vectorizer.transform([input_combined]) \n",
    "    # pull the probabilities from the input\n",
    "    probabilities = emotion_model.predict_proba(input_vector)\n",
    "    # return the probabilities\n",
    "    return probabilities.tolist()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c6299-7a9e-481b-995d-b0cd9bfe4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_search_x(user_input):\n",
    "    \n",
    "    # Convert the user's input into a vector \n",
    "    user_vector = emotion_score(user_input)\n",
    "    \n",
    "    # Ensure scored_music DataFrame has a column for vectors\n",
    "    if 'vector' not in scored_music.columns:\n",
    "        raise ValueError(\"scored_music DataFrame must have a 'vector' column containing song vectors.\")\n",
    "    \n",
    "    # Convert the list of vectors from the scored_music DataFrame into a matrix\n",
    "    song_vectors = np.vstack(scored_music['vector'].values)\n",
    "    \n",
    "    # Calculate cosine similarity for the entire set of song vectors at once\n",
    "    # the 0 index is to turn the array into a list which can then be stored in a data frame\n",
    "    cos_sim = cosine_similarity(np.array(user_vector).reshape(1,-1), song_vectors)[0]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame to store the similarity scores along with song and artist info\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'similarity': cos_sim,\n",
    "        'track': scored_music['song'],\n",
    "        'artist': scored_music['artist']\n",
    "    })\n",
    "    \n",
    "    # Sort by similarity in descending order\n",
    "    sorted_comparison_df = comparison_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # return the top 10\n",
    "    return sorted_comparison_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3905e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18945</th>\n",
       "      <td>0.999684</td>\n",
       "      <td>Mr Blue</td>\n",
       "      <td>Yazoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.999659</td>\n",
       "      <td>Here's Your Letter (Toronto Concert)</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40579</th>\n",
       "      <td>0.999576</td>\n",
       "      <td>I Hate You</td>\n",
       "      <td>Slayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26563</th>\n",
       "      <td>0.999570</td>\n",
       "      <td>Now That It's Over</td>\n",
       "      <td>Everclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>Without A Shot</td>\n",
       "      <td>John Mellencamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23509</th>\n",
       "      <td>0.999286</td>\n",
       "      <td>Wee Wee Hours</td>\n",
       "      <td>Chuck Berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42487</th>\n",
       "      <td>0.999280</td>\n",
       "      <td>Anodyne</td>\n",
       "      <td>Uncle Tupelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15958</th>\n",
       "      <td>0.999264</td>\n",
       "      <td>Sleeping Single</td>\n",
       "      <td>Roxette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>0.999249</td>\n",
       "      <td>Boudicca</td>\n",
       "      <td>Horrible Histories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40280</th>\n",
       "      <td>0.999225</td>\n",
       "      <td>The Wreckers</td>\n",
       "      <td>Rush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity                                 track              artist\n",
       "18945    0.999684                               Mr Blue               Yazoo\n",
       "899      0.999659  Here's Your Letter (Toronto Concert)       Avril Lavigne\n",
       "40579    0.999576                            I Hate You              Slayer\n",
       "26563    0.999570                    Now That It's Over           Everclear\n",
       "8770     0.999426                        Without A Shot     John Mellencamp\n",
       "23509    0.999286                         Wee Wee Hours         Chuck Berry\n",
       "42487    0.999280                               Anodyne        Uncle Tupelo\n",
       "15958    0.999264                       Sleeping Single             Roxette\n",
       "29526    0.999249                              Boudicca  Horrible Histories\n",
       "40280    0.999225                          The Wreckers                Rush"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_search_x(\"i placed at least five different bets on thursday night football and not a single one hit.  I probably lost at least forty dollars.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
