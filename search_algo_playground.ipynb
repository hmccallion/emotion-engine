{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more dependencies\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mccal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even more dependencies\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a set containing all of the english stop words\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion_model.pkl','rb') as file:\n",
    "    emotion_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl','rb') as file:\n",
    "    vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scored_music.pkl','rb') as file:\n",
    "    scored_music = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will be for tinkering with the cosine similarity search algorithm and figuring out how to make it faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the emotion score function\n",
    "\n",
    "def emotion_score(user_input):\n",
    "    # tokenize the input\n",
    "    input_tokens = nltk.word_tokenize(user_input.lower()) \n",
    "    # filter stopwords out of the input\n",
    "    filtered_input_tokens = [word for word in input_tokens if word not in stop_words] \n",
    "    # re-join the filtered tokens\n",
    "    input_combined = ' '.join(filtered_input_tokens) \n",
    "    # feature extraction\n",
    "    input_vector = vectorizer.transform([input_combined]) \n",
    "    # pull the probabilities from the input\n",
    "    probabilities = emotion_model.predict_proba(input_vector)\n",
    "    # return the probabilities\n",
    "    return probabilities.tolist()[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rewrite the song similarity function.  Since we will be computing the similarity with every song vector at once, it will already be shaped properly.\n",
    "<div></div>\n",
    "The only vector that will need to be re-shaped is the vectorized user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1920253255547959,\n",
       " 0.4423441895317889,\n",
       " 0.10115656642592427,\n",
       " 0.1433433982582535,\n",
       " 0.08900427340555789,\n",
       " 0.03212624682367958]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start by creating a vector from a user's input\n",
    "user_vector = emotion_score(\"sample user input written for testing\")\n",
    "user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.03579174590286366, 0.8689770047957636, 0.01...\n",
       "1        [0.06429972188393214, 0.6377869365833222, 0.15...\n",
       "2        [0.5374242825027009, 0.31686309768917464, 0.07...\n",
       "3        [0.13480472056337753, 0.36512886018708607, 0.2...\n",
       "4        [0.9674123512465452, 0.00520893792719057, 0.01...\n",
       "                               ...                        \n",
       "44790    [0.15062559050424443, 0.5088407635755823, 0.05...\n",
       "44791    [0.438188434704547, 0.1918744712386625, 0.0303...\n",
       "44792    [0.16985368845236432, 0.41788928089604205, 0.0...\n",
       "44793    [0.2919489066741162, 0.2975261464479545, 0.074...\n",
       "44794    [0.3067180083139707, 0.26479157366799827, 0.08...\n",
       "Name: vector, Length: 44795, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to be able to compute dot products with this vector and every song vector at once\n",
    "scored_music.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0.03579174590286366, 0.8689770047957636, 0.019480216983298226, 0.032564944744232945, 0.023263061565039773, 0.01992302600880187]),\n",
       "       list([0.06429972188393214, 0.6377869365833222, 0.1520119896560907, 0.0530454841641546, 0.06036502570132249, 0.032490842011177856]),\n",
       "       list([0.5374242825027009, 0.31686309768917464, 0.07247709323584733, 0.02208633081018713, 0.02742763237694463, 0.02372156338514537]),\n",
       "       ...,\n",
       "       list([0.16985368845236432, 0.41788928089604205, 0.08971713182181408, 0.13040927733200505, 0.15285628878492602, 0.039274332712848595]),\n",
       "       list([0.2919489066741162, 0.2975261464479545, 0.07445915237974543, 0.20084836550918847, 0.10241929294489283, 0.03279813604410254]),\n",
       "       list([0.3067180083139707, 0.26479157366799827, 0.08410894800858743, 0.2173920374978352, 0.0970364581197081, 0.029952974391900266])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all we need are the values\n",
    "scored_music.vector.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03579175, 0.868977  , 0.01948022, 0.03256494, 0.02326306,\n",
       "        0.01992303],\n",
       "       [0.06429972, 0.63778694, 0.15201199, 0.05304548, 0.06036503,\n",
       "        0.03249084],\n",
       "       [0.53742428, 0.3168631 , 0.07247709, 0.02208633, 0.02742763,\n",
       "        0.02372156],\n",
       "       ...,\n",
       "       [0.16985369, 0.41788928, 0.08971713, 0.13040928, 0.15285629,\n",
       "        0.03927433],\n",
       "       [0.29194891, 0.29752615, 0.07445915, 0.20084837, 0.10241929,\n",
       "        0.03279814],\n",
       "       [0.30671801, 0.26479157, 0.08410895, 0.21739204, 0.09703646,\n",
       "        0.02995297]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but we also need them to be in a matrix\n",
    "song_matrix = np.vstack(scored_music.vector.values)\n",
    "song_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1920253255547959,\n",
       " 0.4423441895317889,\n",
       " 0.10115656642592427,\n",
       " 0.1433433982582535,\n",
       " 0.08900427340555789,\n",
       " 0.03212624682367958]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19202533, 0.44234419, 0.10115657, 0.1433434 , 0.08900427,\n",
       "       0.03212625])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_array = np.array(user_vector)\n",
    "user_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user array shape:  (6,)\n",
      "song matrix shape:  (44795, 6)\n"
     ]
    }
   ],
   "source": [
    "print( 'user array shape: ',user_array.shape)\n",
    "print('song matrix shape: ',song_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do the dot product for an mxn with a pxq matrix, n and q must be equal.  This is why we need to reshape the user_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_array shape:  (1, 6)\n"
     ]
    }
   ],
   "source": [
    "shaped_user_array = user_array.reshape(1,-1)\n",
    "print( \"user_array shape: \", shaped_user_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do dot products which is part of the cosine similarity procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44795)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(shaped_user_array,song_matrix).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we get the cosine similarity array we need to convert it back to a list so it can be stored in a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44795,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(shaped_user_array,song_matrix)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First write the function that computes the song similarity using sklearn cosine similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
